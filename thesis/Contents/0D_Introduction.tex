\chapter*{Introduction}\label{chap:Introduction} \markboth{\MakeUppercase{Introduction}}{} \phantomsection
\addcontentsline{toc}{chapter}{Introduction}

Solving large problems by writing custom software is a task reserved for large companies with significant allocated investment, or by individuals with many (many) years to dedicate.

The software-engineering problem\textemdash{}spawning the discipline's creation\textemdash{}was\\stated in 1968\cite{mcilroyMassProducedSoftwareComponents1968} and was the culmination of decades of issues in software-development, and the conflict between business requirements and computer-\\scientists' approaches. Notably, mass production of mass customisable software, and separating algorithmic optimisation from business needs, drawing similarities to these processes in [existent] physical engineering fields.

The extreme goal of this thesis is to \textbf{solve the software-engineering problem}.

The software engineering problem is redefined as: \textit{the ability to rapidly solve\\large problems with large custom software projects without needing corre-\\spondingly large teams} (e.g., make the process doable by a single individual\\but modular enough to expand and retract between one and thousands of\\engineers).

Large problems solved with software-engineering [that are focussed on here] include:
\begin{enumerate}
    \item[0.] Data-driven applications with multiple decoupled:
    \begin{itemize}
        \item mobile apps;
        \item web frontend(s);
        \item backend(s).
    \end{itemize}
    \item Scaling deployments to multiple private and public cloud vendors;
    \item Switching between different architectures, including:
    \begin{itemize}
        \item monolithic (self-contained):
        \begin{itemize}
            \item database, server and frontend all running on, e.g., a smartphone xor mainframe.
        \end{itemize}
        \item client/server:
        \begin{itemize}
            \item e.g., with server deployed on cloud.
        \end{itemize}
        \item client/cluster:
        \begin{itemize}
            \item e.g., with servers deployed to multiple clouds;
            \item e.g., with multi-master multi readonly slave config.
        \end{itemize}
        \item peer-to-peer;
    \end{itemize}
    \item Machine-learning tasks with approximate non-niche solutions:
    \begin{itemize}
        \item Maintain best-of-breed metrics (e.g., accuracy) by automatically gro-\\wing the algorithm search-space [database] with the latest from indu-\\stry and academia;
        \item Dynamically explore search-space, picking optimal for your require-\\ments (e.g., accuracy or AUCROC metric).
    \end{itemize}
\end{enumerate}

\section{Themes}

Custom compilers are the core of each solution to each problem throughout this dissertation.

\subsection{Data-driven applications (CDD)}

Chapter~\ref{chap:01} describes a partial solution to the multi-tier application problem\ldots{} defined as: synchronising data models, validation, endpoints, tests, mocks, and documentation between two or more languages/frameworks.

\subsection{Multicloud}

Chapter 2 describes a series of novel cloud vendor client libraries written in C and generated by custom compilers, to keep them synchronised with new endpoints and updated schemas from the particular cloud provider. C is chosen here for maximum portability and interopability, including the ability to be called from hundreds of higher level languages (including: TypeScript, Java, Python, and Dart).

\subsection{Multiarch}

Chapter 3 describes new database deployment architectures, enabling the data layer\textemdash{}e.g., database\textemdash{}to be embedded in the program, interconnected (peer-to-peer), and separated out (client-server), including with complicated configs like multi-master with multi readonly slaves.

\subsection{Multi-ML meta-framework}

Chapter 4 describes a novel multi-ML meta-framework that works across 10 of the most popular open-source Python abstracted ML libraries and frameworks. The sheer amount of new research in this field makes it impossible for most everyone [and especially small teams] to keep up-to-date with the latest develop\\ments. This framework automatically adds the capabilities of each framework into one search space, then expands that search space with `community'\textemdash{}oft: academia or industry\textemdash{}contributed solutions, so that one can confidently say they have the best available algorithm for their non-niche ML problem (e.g., binary classification problems).

\section{Multi-ML cross-platform meta-programming at scale using compiler tech and C}

The culmination of all the chapters to deliver projects for real business clients, charities, and just-for-fun!

Cross-platform means native quality, performance, and resource utilisation across multiple platforms including: mobile, desktop, web, and server. At scale means in a monolithic setting, all the way out to 10,000 servers. C means portability and interoperability; the oldest standard was selected (C89) which worked 30 years ago and should work 30 years into the future. Compiler tech is the theme glueing all the concepts together.

\section{Case studies}

To avoid this becoming an armchair ivory-tower considered solution, throughout this thesis multiple charitable and commercial projects were conducted utilising the new methodology and corresponding compilers, notably:

\subsection{Diabetic Retinopathy screening at Point of Care}

Although this project was conducted before this thesis started, a lot of the probl-\\ems found here inspired this thesis, in particular the multi-ML theme combined with [more] CDD to let the surgeons modify their screening criteria. Here this meant four categories for two binary classification problems:
\begin{enumerate}
    \item[0.] Diabetic Retinopathy (DR)
    \item No DR
    \item[a.] Gradable
    \item[b.] Ungradable
\end{enumerate}

Manual\textemdash{}non compiler-driven\textemdash{}programming was done for the majority of this project. But it did enable the surgeons to triage people [label images], from categories they created. The machine-learning process was manually kicked off\ldots~which also inspired the \textit{theoretical workflow} of taking the engineer out of the loop, like so:
\begin{enumerate}
    \item[0.] surgeon register/login;
    \item PI surgeon name study and set password;
    \item PI surgeon create labels and data field types:
    \begin{itemize}
        \item e.g., images, video, categorical and continuous form fields.
    \end{itemize}
    \item PI surgeon invite others to contribute data;
    \item PI surgeon invite others to label data;
    \item data contributed;
    \item surgeon(s) label data (if multiple then score intraobserver agreement);
    \item PI surgeon kickoff automated classification;
    \item publish classification accuracy;
    \item PI surgeon design app for others to use with the new automated classifier to provide an instant classification for in-field screening.
    \item PI surgeon clicks `Deploy' button, stack is deployed to cloud environment, website, Android [Google Play] and iPhone/iPad [Apple AppStore] app stores;
    \item surgeon(s) label new data and the cycle can repeat.
\end{enumerate}

\subsection{Triage in an Emergency Department}

Taking the concept from the previous case study, this time turning theory into practise.

\subsection{Glaucoma screening of the general population}

\section{Philosophy}

In addition to the unique programming methodology of considering every devel-\\opment problem as a compiler problem, this dissertation takes a hardline \textbf{open-source} approach to everything. All technology is released under permissive licen-\\sing; enabling use in both commercial and noncommercial settings. Large\textemdash{}and sometimes significant\textemdash{}numbers of open-source contributions were done [by me] throughout this thesis, fixing vendor bugs and expanding their codebases to supp-\\ort novel workflows important to the subprojects of this thesis\ldots~tabulated below are only a selection:

\begin{tabularx}{\textwidth}{|X|X|X|X|}
    \hline
    \textbf{Organisation} & \textbf{Project} & \textbf{\# commits} & \textbf{\# LoC} \\
    \hline
    Google & TensorFlow & 187 & 2770 \\
    \hline
\end{tabularx}

\clearpage

\bibliographystyle{IEEEtranN}
\bibliography{Thesis}
